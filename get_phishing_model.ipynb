{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Phishing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jnHrIST-_Nsy"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x8EFATg44Q7Q",
        "outputId": "731d5123-2608-41e1-ccdd-8187eb7b6e1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Pytorch Libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Model Libraries\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_validate, train_test_split\n",
        "from sklearn.metrics import log_loss, accuracy_score\n",
        "from sklearn import ensemble\n",
        "\n",
        "# Visualisation Libraries\n",
        "from tqdm import tqdm_notebook\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# General\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import gc\n",
        "import shutil\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LbjBFsrcCQcC"
      },
      "source": [
        "## Load Kaggle Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ewrWVssNCSNl",
        "colab": {}
      },
      "source": [
        "data_url = \"https://raw.githubusercontent.com/daniohren/phishing/master/kaggle_dataset_trimmed.csv?token=APQ4HLVUV5VVEETNGR6Z7VK6XAZ5E\"\n",
        "\n",
        "data = pd.read_csv(data_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PGDv7NoSKRIm"
      },
      "source": [
        "## Display sample of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ceydnWpNMxK4",
        "outputId": "dc59202e-bcdf-42df-86f7-985238aabcb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "data.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>having_IPhaving_IP_Address</th>\n",
              "      <th>URLURL_Length</th>\n",
              "      <th>Shortining_Service</th>\n",
              "      <th>having_At_Symbol</th>\n",
              "      <th>double_slash_redirecting</th>\n",
              "      <th>Prefix_Suffix</th>\n",
              "      <th>having_Sub_Domain</th>\n",
              "      <th>SSLfinal_State</th>\n",
              "      <th>Domain_registeration_length</th>\n",
              "      <th>Favicon</th>\n",
              "      <th>port</th>\n",
              "      <th>HTTPS_token</th>\n",
              "      <th>Request_URL</th>\n",
              "      <th>URL_of_Anchor</th>\n",
              "      <th>Links_in_tags</th>\n",
              "      <th>SFH</th>\n",
              "      <th>Submitting_to_email</th>\n",
              "      <th>Abnormal_URL</th>\n",
              "      <th>Redirect</th>\n",
              "      <th>on_mouseover</th>\n",
              "      <th>RightClick</th>\n",
              "      <th>popUpWidnow</th>\n",
              "      <th>Iframe</th>\n",
              "      <th>age_of_domain</th>\n",
              "      <th>DNSRecord</th>\n",
              "      <th>web_traffic</th>\n",
              "      <th>Page_Rank</th>\n",
              "      <th>Google_Index</th>\n",
              "      <th>Links_pointing_to_page</th>\n",
              "      <th>Statistical_report</th>\n",
              "      <th>Result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  having_IPhaving_IP_Address  ...  Statistical_report  Result\n",
              "0      1                          -1  ...                  -1      -1\n",
              "1      2                           1  ...                   1      -1\n",
              "2      3                           1  ...                  -1      -1\n",
              "3      4                           1  ...                   1      -1\n",
              "4      5                           1  ...                   1       1\n",
              "5      6                          -1  ...                  -1       1\n",
              "6      7                           1  ...                  -1      -1\n",
              "7      8                           1  ...                   1      -1\n",
              "8      9                           1  ...                   1       1\n",
              "9     10                           1  ...                   1      -1\n",
              "\n",
              "[10 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hV9PVMsAZNoi"
      },
      "source": [
        "## Display Data Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YGog_l-uZNBM",
        "outputId": "5134511d-287d-4816-9324-3ca32eb5596e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>having_IPhaving_IP_Address</th>\n",
              "      <th>URLURL_Length</th>\n",
              "      <th>Shortining_Service</th>\n",
              "      <th>having_At_Symbol</th>\n",
              "      <th>double_slash_redirecting</th>\n",
              "      <th>Prefix_Suffix</th>\n",
              "      <th>having_Sub_Domain</th>\n",
              "      <th>SSLfinal_State</th>\n",
              "      <th>Domain_registeration_length</th>\n",
              "      <th>...</th>\n",
              "      <th>popUpWidnow</th>\n",
              "      <th>Iframe</th>\n",
              "      <th>age_of_domain</th>\n",
              "      <th>DNSRecord</th>\n",
              "      <th>web_traffic</th>\n",
              "      <th>Page_Rank</th>\n",
              "      <th>Google_Index</th>\n",
              "      <th>Links_pointing_to_page</th>\n",
              "      <th>Statistical_report</th>\n",
              "      <th>Result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11055.000000</td>\n",
              "      <td>11055.000000</td>\n",
              "      <td>11055.000000</td>\n",
              "      <td>11055.000000</td>\n",
              "      <td>11055.000000</td>\n",
              "      <td>11055.000000</td>\n",
              "      <td>11055.000000</td>\n",
              "      <td>11055.000000</td>\n",
              "      <td>11055.000000</td>\n",
              "      <td>11055.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>11055.000000</td>\n",
              "      <td>11055.000000</td>\n",
              "      <td>11055.000000</td>\n",
              "      <td>11055.000000</td>\n",
              "      <td>11055.000000</td>\n",
              "      <td>11055.000000</td>\n",
              "      <td>11055.000000</td>\n",
              "      <td>11055.000000</td>\n",
              "      <td>11055.000000</td>\n",
              "      <td>11055.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5528.000000</td>\n",
              "      <td>0.313795</td>\n",
              "      <td>-0.633198</td>\n",
              "      <td>0.738761</td>\n",
              "      <td>0.700588</td>\n",
              "      <td>0.741474</td>\n",
              "      <td>-0.734962</td>\n",
              "      <td>0.063953</td>\n",
              "      <td>0.250927</td>\n",
              "      <td>-0.336771</td>\n",
              "      <td>...</td>\n",
              "      <td>0.613388</td>\n",
              "      <td>0.816915</td>\n",
              "      <td>0.061239</td>\n",
              "      <td>0.377114</td>\n",
              "      <td>0.287291</td>\n",
              "      <td>-0.483673</td>\n",
              "      <td>0.721574</td>\n",
              "      <td>0.344007</td>\n",
              "      <td>0.719584</td>\n",
              "      <td>0.113885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3191.447947</td>\n",
              "      <td>0.949534</td>\n",
              "      <td>0.766095</td>\n",
              "      <td>0.673998</td>\n",
              "      <td>0.713598</td>\n",
              "      <td>0.671011</td>\n",
              "      <td>0.678139</td>\n",
              "      <td>0.817518</td>\n",
              "      <td>0.911892</td>\n",
              "      <td>0.941629</td>\n",
              "      <td>...</td>\n",
              "      <td>0.789818</td>\n",
              "      <td>0.576784</td>\n",
              "      <td>0.998168</td>\n",
              "      <td>0.926209</td>\n",
              "      <td>0.827733</td>\n",
              "      <td>0.875289</td>\n",
              "      <td>0.692369</td>\n",
              "      <td>0.569944</td>\n",
              "      <td>0.694437</td>\n",
              "      <td>0.993539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2764.500000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5528.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8291.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>11055.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              index  having_IPhaving_IP_Address  URLURL_Length  \\\n",
              "count  11055.000000                11055.000000   11055.000000   \n",
              "mean    5528.000000                    0.313795      -0.633198   \n",
              "std     3191.447947                    0.949534       0.766095   \n",
              "min        1.000000                   -1.000000      -1.000000   \n",
              "25%     2764.500000                   -1.000000      -1.000000   \n",
              "50%     5528.000000                    1.000000      -1.000000   \n",
              "75%     8291.500000                    1.000000      -1.000000   \n",
              "max    11055.000000                    1.000000       1.000000   \n",
              "\n",
              "       Shortining_Service  having_At_Symbol  double_slash_redirecting  \\\n",
              "count        11055.000000      11055.000000              11055.000000   \n",
              "mean             0.738761          0.700588                  0.741474   \n",
              "std              0.673998          0.713598                  0.671011   \n",
              "min             -1.000000         -1.000000                 -1.000000   \n",
              "25%              1.000000          1.000000                  1.000000   \n",
              "50%              1.000000          1.000000                  1.000000   \n",
              "75%              1.000000          1.000000                  1.000000   \n",
              "max              1.000000          1.000000                  1.000000   \n",
              "\n",
              "       Prefix_Suffix  having_Sub_Domain  SSLfinal_State  \\\n",
              "count   11055.000000       11055.000000    11055.000000   \n",
              "mean       -0.734962           0.063953        0.250927   \n",
              "std         0.678139           0.817518        0.911892   \n",
              "min        -1.000000          -1.000000       -1.000000   \n",
              "25%        -1.000000          -1.000000       -1.000000   \n",
              "50%        -1.000000           0.000000        1.000000   \n",
              "75%        -1.000000           1.000000        1.000000   \n",
              "max         1.000000           1.000000        1.000000   \n",
              "\n",
              "       Domain_registeration_length  ...   popUpWidnow        Iframe  \\\n",
              "count                 11055.000000  ...  11055.000000  11055.000000   \n",
              "mean                     -0.336771  ...      0.613388      0.816915   \n",
              "std                       0.941629  ...      0.789818      0.576784   \n",
              "min                      -1.000000  ...     -1.000000     -1.000000   \n",
              "25%                      -1.000000  ...      1.000000      1.000000   \n",
              "50%                      -1.000000  ...      1.000000      1.000000   \n",
              "75%                       1.000000  ...      1.000000      1.000000   \n",
              "max                       1.000000  ...      1.000000      1.000000   \n",
              "\n",
              "       age_of_domain     DNSRecord   web_traffic     Page_Rank  Google_Index  \\\n",
              "count   11055.000000  11055.000000  11055.000000  11055.000000  11055.000000   \n",
              "mean        0.061239      0.377114      0.287291     -0.483673      0.721574   \n",
              "std         0.998168      0.926209      0.827733      0.875289      0.692369   \n",
              "min        -1.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
              "25%        -1.000000     -1.000000      0.000000     -1.000000      1.000000   \n",
              "50%         1.000000      1.000000      1.000000     -1.000000      1.000000   \n",
              "75%         1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "max         1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "       Links_pointing_to_page  Statistical_report        Result  \n",
              "count            11055.000000        11055.000000  11055.000000  \n",
              "mean                 0.344007            0.719584      0.113885  \n",
              "std                  0.569944            0.694437      0.993539  \n",
              "min                 -1.000000           -1.000000     -1.000000  \n",
              "25%                  0.000000            1.000000     -1.000000  \n",
              "50%                  0.000000            1.000000      1.000000  \n",
              "75%                  1.000000            1.000000      1.000000  \n",
              "max                  1.000000            1.000000      1.000000  \n",
              "\n",
              "[8 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tfbIccoF_VQp"
      },
      "source": [
        "## Shuffle Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HX98k6hhbEyK",
        "colab": {}
      },
      "source": [
        "# Shuffle dataset\n",
        "data = data.sample(frac = 1).reset_index(drop = True)\n",
        "data_x = data.drop(['index', 'Result'], axis = 1).to_numpy()\n",
        "data_y = data['Result'].to_numpy()\n",
        "class_list = sorted(list(set(data_y)))\n",
        "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.33, stratify=data_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P1cFlkpJGUml"
      },
      "source": [
        "## Add new features\n",
        "Engineering 2 additional columns:\n",
        "1. Sum of all features.\n",
        "2. Number of non-zero features.\n",
        "3. Variance of all features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2OgtYnt_GTt-",
        "colab": {}
      },
      "source": [
        "sum_x = np.sum(train_x, axis = 1).reshape(-1, 1)\n",
        "non_zeros_x = np.count_nonzero(train_x, axis = 1).reshape(-1, 1)\n",
        "var_x = np.var(train_x, axis = 1).reshape(-1, 1)\n",
        "new_train_x = np.hstack((train_x, sum_x, var_x, non_zeros_x))\n",
        "\n",
        "sum_x = np.sum(test_x, axis = 1).reshape(-1, 1)\n",
        "non_zeros_x = np.count_nonzero(test_x, axis = 1).reshape(-1, 1)\n",
        "var_x = np.var(test_x, axis = 1).reshape(-1, 1)\n",
        "new_test_x = np.hstack((test_x, sum_x, var_x, non_zeros_x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2yj1MtFHJ24p"
      },
      "source": [
        "## Plot Train Data Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ujn3SSgqFqpU",
        "outputId": "f04b2539-0e57-41ab-ae2a-dd8eb0a0ee61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "sns.set(style=\"darkgrid\")\n",
        "ax = sns.countplot(x = \"Result\", data = data, order = class_list)\n",
        "ax.set_xlabel(\"Classes\")\n",
        "ax.set_ylabel(\"Number\")\n",
        "labels = ax.get_xticklabels()\n",
        "for label in labels:\n",
        "    label.set_rotation(60)\n",
        "plt.rcParams['figure.figsize'] = (5,5)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HntYpdqCoHbu"
      },
      "source": [
        "## Try default parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AUWGJpdfiGau",
        "outputId": "8fa62a01-2ca7-4224-8899-5ec1192094fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        " xgb_model = xgb.XGBClassifier(objective = 'binary:logistic', gamma = 1,  tree_method = 'gpu_hist', nthread = -1, verbosity = 2)\n",
        " xgb_model.fit(new_train_x, train_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "XGBoostError",
          "evalue": "[17:38:32] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.0.0\\src\\gbm\\gbtree.h:308: Check failed: gpu_predictor_: ",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-11-655339817b28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mxgb_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'binary:logistic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mtree_method\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'gpu_hist'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbosity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mxgb_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_train_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    821\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    207\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1247\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0;32m   1248\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1249\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1250\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \"\"\"\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mXGBoostError\u001b[0m: [17:38:32] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.0.0\\src\\gbm\\gbtree.h:308: Check failed: gpu_predictor_: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DU7vPXLElEMH",
        "colab": {}
      },
      "source": [
        "xgb_model.score(new_test_x,test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rkXuzfZu7dt_"
      },
      "source": [
        "## Grid Search using XGBoost Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8eGTSP9L1x1b",
        "colab": {}
      },
      "source": [
        " xgb_model = xgb.XGBClassifier(objective = 'binary:logistic', gamma = 1,  tree_method = 'gpu_hist', nthread = -1, verbosity = 2)\n",
        " params = {\n",
        "     'learning_rate' : [0.05, 0.1, 0.5],\n",
        "     'n_estimators' : [200, 400, 600],\n",
        "     'max_depth' : [6, 9, 12],\n",
        "     'subsample': [0.5, 0.8, 1],\n",
        "     'colsample_bytree': [0.5, 0.8, 1],\n",
        "     'colsample_bylevel': [0.5, 0.8, 1],\n",
        " }\n",
        " xgb_gsm = RandomizedSearchCV(xgb_model, params, n_iter = 10, scoring = ['neg_log_loss', 'accuracy'], n_jobs = -1 , \n",
        "                              refit = 'neg_log_loss', cv = 4, verbose = 2, random_state = 7)\n",
        " xgb_gsm.fit(new_train_x, train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WpA1CoBupx9-",
        "colab": {}
      },
      "source": [
        "xgb_gsm.best_params_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Be_yMf2bDRJf"
      },
      "source": [
        "## Best Params\n",
        "\n",
        "{'colsample_bylevel': 1,\n",
        " 'colsample_bytree': 1,\n",
        " 'learning_rate': 0.1,\n",
        " 'max_depth': 9,\n",
        " 'n_estimators': 200,\n",
        " 'subsample': 0.8}\n",
        "\n",
        "## Best Model\n",
        " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "              colsample_bynode=1, colsample_bytree=1, gamma=1,\n",
        "              learning_rate=0.1, max_delta_step=0, max_depth=9,\n",
        "              min_child_weight=1, missing=None, n_estimators=200, n_jobs=1,\n",
        "              nthread=-1, objective='multi:softprob', random_state=0,\n",
        "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "              silent=None, subsample=0.8, tree_method='gpu_hist', verbosity=2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D62wq0INDrU0",
        "colab": {}
      },
      "source": [
        "xgb_model_best = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "                colsample_bynode=1, colsample_bytree=1, gamma=1,\n",
        "                learning_rate=0.1, max_delta_step=0, max_depth=12,\n",
        "                min_child_weight=1, missing=None, n_estimators=200, n_jobs=1,\n",
        "                nthread=-1, objective='binary:logistic', random_state=0,\n",
        "                reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "                silent=None, subsample=1, tree_method='gpu_hist', verbosity=2)\n",
        "xgb_model_best.fit(train_x,train_y)\n",
        "\n",
        "# save the model to disk\n",
        "filename = 'finalized_model.pkl'\n",
        "pickle.dump(xgb_model_best, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6TRcgHiOLKj2"
      },
      "source": [
        "## Predict on Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cyvoxbYYLJ2X",
        "colab": {}
      },
      "source": [
        "xgb_model_best.score(test_x,test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PqxaCeO__eIr"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4vadpiCsvdle",
        "colab": {}
      },
      "source": [
        "## Testing\n",
        "sk_folds = StratifiedKFold(n_splits = 3)\n",
        "\n",
        "tot_loss = 0\n",
        "tot_acc = 0\n",
        "count = 1\n",
        "for train_idx, val_idx in sk_folds.split(new_train_x, train_y):\n",
        "    x_train, y_train = new_train_x[train_idx], train_y[train_idx]\n",
        "    x_val, y_val = new_train_x[val_idx], train_y[val_idx]\n",
        "    xgb_model_best.fit(x_train, y_train)\n",
        "\n",
        "    # Train\n",
        "    train_preds = xgb_model_best.predict_proba(x_train)\n",
        "    train_loss = log_loss(y_train, train_preds)\n",
        "    \n",
        "    # Val\n",
        "    val_preds = xgb_model_best.predict_proba(x_val)\n",
        "    val_loss = log_loss(y_val, val_preds)\n",
        "    val_acc = accuracy_score(y_val, xgb_model_best.predict(x_val))\n",
        "\n",
        "    print(\"Split: {0}\\tTraining Loss:{1:.4f}\\tValidation Loss:{2:.4f}\".format(count, train_loss, val_loss))\n",
        "\n",
        "    # Total\n",
        "    tot_loss += val_loss\n",
        "    tot_acc += val_acc\n",
        "    count+=1\n",
        "print(\"\\nAverage Loss:{}\\nAverage Accuracy:{}\".format(tot_loss/3, (tot_acc/3)*100))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}